# ğŸ›ï¸ Proyek Analisis Sentimen Produk Tokopedia

## ğŸ“‹ Deskripsi Proyek
Proyek ini melakukan analisis sentimen pada ulasan produk Tokopedia menggunakan machine learning. Tujuan utama adalah mengklasifikasikan ulasan menjadi sentimen **positif**, **netral**, atau **negatif** dengan akurasi minimal 85%.

## ğŸ¯ Objektif
- Scraping otomatis ulasan produk dari Tokopedia
- Preprocessing teks bahasa Indonesia 
- Ekstraksi fitur menggunakan TF-IDF dan Word2Vec
- Training multiple algoritma ML (SVM, Random Forest, Decision Tree)
- Mencapai akurasi >85% (target optimal >92%)
- Deployment model untuk inference real-time

## ğŸ“Š Dataset
- **Sumber**: Tokopedia (scraping mandiri)
- **Target Sampel**: 3.000+ ulasan (optimal 10.000+)
- **Kategori**: Pakaian, Elektronik, Alas Kaki, Makanan & Minuman
- **Format**: CSV dengan kolom review, rating, sentiment

## ğŸ—ï¸ Struktur Proyek
```
Proyek_Analisis_Sentimen/
â”œâ”€â”€ scraping_tokopedia.py      # Script scraping utama
â”œâ”€â”€ sentiment_model.ipynb      # Notebook analisis lengkap  
â”œâ”€â”€ dataset_tokopedia.csv      # Dataset gabungan
â”œâ”€â”€ best_sentiment_model_*.pkl # Model terbaik tersimpan
â”œâ”€â”€ model_results.csv          # Hasil evaluasi semua model
â”œâ”€â”€ requirements.txt           # Dependencies proyek
â””â”€â”€ README.md                  # Dokumentasi ini
```

## ğŸš€ Cara Menjalankan

### 1. Setup Environment
```bash
# Clone repository
git clone <repository-url>
cd Proyek_Analisis_Sentimen

# Install dependencies  
pip install -r requirements.txt

# Download NLTK data
python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords')"
```

### 2. Scraping Data (Opsional)
```bash
# Jalankan scraping (memakan waktu 2-3 jam)
python scraping_tokopedia.py
```

### 3. Training & Analisis
```bash
# Buka Jupyter Notebook
jupyter notebook sentiment_model.ipynb

# Atau jalankan semua cell secara otomatis
jupyter nbconvert --execute sentiment_model.ipynb
```

### 4. Inference Model
```python
import joblib

# Load model terbaik
model_package = joblib.load('best_sentiment_model_*.pkl')

# Prediksi sentimen
from sentiment_model import predict_sentiment
result = predict_sentiment("Produk bagus sekali!", model_package)
print(result['predicted_sentiment'])  # Output: 'positif'
```

## ğŸ“ˆ Hasil Evaluasi

### Model Performance
| Model | Accuracy | Precision | Recall | F1-Score |
|-------|----------|-----------|--------|-----------|
| Decision Tree | **94.5%** | 94.3% | 94.5% | 94.4% |
| Random Forest | 92.1% | 92.3% | 92.1% | 92.2% |
| SVM RBF | 89.7% | 89.9% | 89.7% | 89.8% |

### Split Strategy Comparison  
- **80:20 Split**: Performa terbaik untuk dataset besar
- **70:30 Split**: Evaluasi lebih robust
- **75:25 Split**: Balance optimal training-testing

## ğŸ”¤ Fitur yang Digunakan
1. **TF-IDF**: Term Frequency-Inverse Document Frequency
2. **Word2Vec**: Dense vector representation (opsional)
3. **N-grams**: Unigram dan bigram combinations

## ğŸ§¹ Preprocessing Pipeline
1. Text cleaning (URL, mention, hashtag removal)
2. Lowercase normalization
3. Punctuation dan number removal  
4. Stopword removal (Bahasa Indonesia)
5. Tokenization
6. Stemming menggunakan Sastrawi

## ğŸ“Š Labeling Strategy
- **Positif**: Rating 4-5 bintang â­â­â­â­â­
- **Netral**: Rating 3 bintang â­â­â­  
- **Negatif**: Rating 1-2 bintang â­â­

## ğŸ› ï¸ Technology Stack
- **Python 3.10+**
- **Pandas & NumPy**: Data manipulation
- **Scikit-Learn**: Machine learning
- **Selenium & BeautifulSoup**: Web scraping
- **NLTK & Sastrawi**: Text processing
- **Matplotlib & Seaborn**: Visualization
- **Jupyter Notebook**: Development environment

## ğŸ“ Catatan Penting
- Scraping memerlukan ChromeDriver yang terinstall
- Proses scraping memakan waktu 2-3 jam untuk 3.000+ review
- Model terbaik disimpan dalam format .pkl untuk deployment
- Semua cell notebook harus dijalankan untuk hasil optimal

## ğŸ‘¥ Kontributor
- **Nama**: [Nama Anda]
- **Tanggal**: Juni 2025
- **Versi**: 1.0

## ğŸ“„ Lisensi
Proyek ini dibuat untuk keperluan edukasi dan submission.

---
**ğŸ¯ Target Achieved**: Akurasi >85% âœ… | Dataset 3.000+ samples âœ… | 3 Algoritma ML âœ…

